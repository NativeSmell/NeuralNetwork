{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.NeuralNetwork import *\n",
    "import src.DataHandler as dhm\n",
    "import src.Analysis as analys\n",
    "%matplotlib notebook\n",
    "\n",
    "dataSet = 'mnist'\n",
    "\n",
    "splitRate = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117bed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10000 of 10000) |###################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of learning data set: 7000\n",
      "Size of validation data set: 3000\n",
      "Size of testing data set: 10000\n"
     ]
    }
   ],
   "source": [
    "dh = dhm.DataHandler()\n",
    "\n",
    "viewImageIndex = 10\n",
    "\n",
    "images_train = []\n",
    "labels_train = []\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "if dataSet == 'mnist':\n",
    "    \n",
    "    path = 'data/mnist'\n",
    "    \n",
    "    mndata = MNIST(path)\n",
    "\n",
    "    images_train, labels_train = mndata.load_training()\n",
    "    images_test, labels_test = mndata.load_testing()\n",
    "\n",
    "    pixels = np.array(images_test[viewImageIndex]).reshape(28,28)\n",
    "    \n",
    "    \n",
    "if dataSet == 'cifar': \n",
    "    \n",
    "    path = 'data/cifar/'\n",
    "    \n",
    "    files = ['data_batch_1' , 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "    \n",
    "    for file in files:\n",
    "    \n",
    "        f = open(path + file, 'rb')\n",
    "        tupled_data= pickle.load(f, encoding='bytes')\n",
    "    \n",
    "        f.close()\n",
    "        \n",
    "        images_train += tupled_data[b'data'].tolist()\n",
    "        labels_train += tupled_data[b'labels']\n",
    "        \n",
    "            \n",
    "    f = open(path + 'test_batch', 'rb')\n",
    "    tupled_data= pickle.load(f, encoding='bytes')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    images_test = tupled_data[b'data'].tolist()\n",
    "    labels_test = tupled_data[b'labels']    \n",
    "    \n",
    "    images_train = [dh.toYCbCr(pixels) for pixels in images_train]\n",
    "    images_test = [dh.toYCbCr(pixels) for pixels in images_test]\n",
    "    \n",
    "    #pixels = np.transpose(np.reshape(tupled_data[b'data'][viewImageIndex],(3, 32,32)), (1,2,0))\n",
    "    pixels = images_test[viewImageIndex]\n",
    "    \n",
    "    #pixels = dh.toYCbCr(pixels)\n",
    "    \n",
    "    pixels = np.array(pixels).reshape(32,32)    \n",
    "    \n",
    "label = labels_test[viewImageIndex]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pixels, cmap = 'gray')\n",
    "plt.title('This is ' + str(label))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "images_train = images_train[:10000]\n",
    "labels_train = labels_train[:10000]\n",
    "\n",
    "images_train = dh.maxNorm(images_train,_max = 255)\n",
    "\n",
    "images_train, images_val = dh.split(images_train, rate = splitRate)\n",
    "labels_train, labels_val = dh.split(labels_train, rate = splitRate)\n",
    "    \n",
    "print(\"Size of learning data set: \" + str(len(images_train)))\n",
    "print(\"Size of validation data set: \" + str(len(images_val)))\n",
    "print(\"Size of testing data set: \" + str(len(images_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(images_train[0])\n",
    "output_dim = int(10)\n",
    "\n",
    "\n",
    "model = Sequental(input_dim)\n",
    "model.add(Dense(64, activation = 'relu', dropoutProp = 0.))\n",
    "model.add(Dense(32, activation = 'linear', dropoutProp = 0.))\n",
    "model.add(Dense(32, activation = 'relu', dropoutProp = 0.))\n",
    "model.add(Dense(16, activation = 'linear', dropoutProp = 0.))\n",
    "model.add(Dense(output_dim, activation = 'sigmoid', dropoutProp = 0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (70.0 of 70.0) |#####################| Elapsed Time: 0:00:29 Time: 0:00:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% (6912 of 7000) |#################### | Elapsed Time: 0:00:05 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% (2925 of 3000) |#################### | Elapsed Time: 0:00:02 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 - loss(MSE): 0.0757341326498 - accuracy: 0.3434285714285714 - val_loss(MSE): 0.0760670025524 - val_accuracy: 0.3446666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (70.0 of 70.0) |#####################| Elapsed Time: 0:00:31 Time: 0:00:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (6994 of 7000) |#################### | Elapsed Time: 0:00:05 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% (2963 of 3000) |#################### | Elapsed Time: 0:00:03 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100 - loss(MSE): 0.0653663894001 - accuracy: 0.4695714285714286 - val_loss(MSE): 0.066059802769 - val_accuracy: 0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% (23 of 70.0) |#######                | Elapsed Time: 0:00:10 ETA:  0:00:23"
     ]
    }
   ],
   "source": [
    "history = model.fit(images_train, labels_train, images_val, labels_val,\n",
    "          numOfEpochs = 100, earlyStopAcc = 0.001,\n",
    "          lossMetric = 'MSE', optimizerType = 'backProp',\n",
    "          batchSize = 100, learningRate = 0.1,\n",
    "          momentum = 0, patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = analys.Analysis()\n",
    "\n",
    "an.buildPlot([history['loss'] , history['val_loss'] ], ['r','b'], ['loss','val_loss'],\n",
    "             dependence = None, showAt = 0, showFor = 0, savePath = None,\n",
    "                  show = True, title = 'loss', xlabel = 'Epoch', ylabel = 'loss',grid = True)\n",
    "\n",
    "an.buildPlot([history['accuracy'] , history['val_accuracy'] ], ['r','b'], ['accuracy','val_accuracy'],\n",
    "             dependence = None, showAt = 0, showFor = 0, savePath = None,\n",
    "                  show = True, title = 'accuracy', xlabel = 'Epoch', ylabel = 'loss',grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = dh.maxNorm(images_test,_max = 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, loss = model.evaluate(images_test,labels_test)\n",
    "\n",
    "print('test_accuracy: ' + str(acc) + ' - test_loss: ' + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_List = []\n",
    "\n",
    "for image in images_test:\n",
    "    predicted_List.append(np.argmax(model.predict(image)))\n",
    "    \n",
    "addPlot = False\n",
    "show = False\n",
    "\n",
    "for i in range(0,10):    \n",
    "    \n",
    "    predict = []\n",
    "    true = []\n",
    "    \n",
    "    if i == 9:\n",
    "        show = True\n",
    "    \n",
    "    for j in range(len(labels_test)):\n",
    "       \n",
    "        if labels_test[j] == i:\n",
    "            true.append(1)\n",
    "        else:\n",
    "            true.append(0)\n",
    "            \n",
    "        if predicted_List[j] == i :\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "\n",
    "    fpr,tpr, roc_auc = an.rocCurve(predict,true)\n",
    "    \n",
    "    an.buildPlot([[fpr,tpr],[[0,1],[0,1]]], \n",
    "             ['-','g--'],\n",
    "             [str(i) + ' class (area = {})'.format(roc_auc), None],\n",
    "             dependence = [True,True], show = show,\n",
    "             title = 'ROC-curve ',\n",
    "             xlabel = 'False Positive Rate',\n",
    "             ylabel = 'True Positive Rate',\n",
    "             savePath = None,\n",
    "             showAt = 0, showFor = 0, addPlot = addPlot)\n",
    "    \n",
    "    addPlot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
